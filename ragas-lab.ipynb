{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c27e89",
   "metadata": {},
   "source": [
    "# Using RAGAs to Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe7713",
   "metadata": {},
   "source": [
    "## _Why evaluate a RAG_?\n",
    "\n",
    "Evaluation tells you what actually works and what fails. For a RAG system you’re not just testing an LLM — you’re testing a pipeline:\n",
    "\n",
    "Retriever quality (are relevant chunks returned?)\n",
    "\n",
    "Generator quality given context (is the answer correct/faithful?)\n",
    "\n",
    "End-to-end user experience (latency, cost, robustness, safety)\n",
    "\n",
    "Without evaluation you’ll be fixing the wrong thing (tuning prompts when retrieval is the real problem, or vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896058d1",
   "metadata": {},
   "source": [
    "- [x] create a testset\n",
    "- [ ] what all is needed in the test set? \n",
    "- [ ] why do we need the test set?\n",
    "- [ ] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a031a",
   "metadata": {},
   "source": [
    "### Getting Transcript Data of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b450eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb486d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytt_api = YouTubeTranscriptApi()\n",
    "video_id = \"P14cRV-m6ZY\"\n",
    "fetched_transcript = ytt_api.fetch(video_id,languages=[\"en\",\"hi\"])\n",
    "\n",
    "transcript = \" \".join(snippet.text for snippet in fetched_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e245a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e122f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(video_id):\n",
    "   ytt_api = YouTubeTranscriptApi()\n",
    "   fetched_transcript = ytt_api.fetch(video_id,languages=[\"en\",\"hi\"])\n",
    "\n",
    "   transcript = \" \".join(snippet.text for snippet in fetched_transcript)\n",
    "   return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44386dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "transcript_file = \"./transcript.txt\"\n",
    "loader = TextLoader(transcript_file)\n",
    "documents = loader.load()\n",
    "\n",
    "# so we basically need a `Document` object to proceed either create the object from the text you have or provide the file. i've choosen the latter way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2310be",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": \"llama-3.3-70b-versatile\",  # or other model IDs\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": None,\n",
    "    \"top_p\": 0.8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a012e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from ragas.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# llm model is groq \n",
    "generator_llm = LangchainLLMWrapper(ChatGroq(\n",
    "   model=config[\"model\"],\n",
    "   temperature=config['temperature']\n",
    "))\n",
    "\n",
    "# embedding model is google embedding model \n",
    "generator_embeddings = LangchainEmbeddingsWrapper(GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "\n",
    "dataset = generator.generate_with_langchain_docs(documents, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcd468c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
